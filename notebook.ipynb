{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "274979b6-5a29-4a7e-8a0c-e07491aa9de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Final Project**\n",
    "\n",
    "This is a project doing some basic data analysis of IMDB movie data and associated wiki streaming events. It should be completed by groups of no less than 2 students and no more than 4 students. Each member of the group should have at least a few commits associated in the project repo.\n",
    "\n",
    "## **Scoring**\n",
    "\n",
    "The code must run and provide the correct answers . 1/2 points\n",
    "The remainder will come from notebook organization, code comments, etc .\n",
    "For the questions that have answers, please also provide those in markdown cells in the notebook, and/or part of a mardown file in the repo .\n",
    "All relevant code should be shared via a shared Git repository. Additionally, you will send an email to joe@adaltas.com when the project has been submitted . Please ensure that the names of all participants are included in the repo and in the submission email . Note: For full credit the code must run with little to no extra input from the end user, and, any extra input that is required must be clearly documented and explained. Also note, any question that is at least attempted will be awarded with partial credit provided there is a corresponding explanation of the difficulties faced.\n",
    "\n",
    "## **Questions**\n",
    "\n",
    "  1 - load data from here. This should be done using a notebook cell and not a manual process to import the data. NOTE: You may not need all of the datasets, but you will be utilizing most of them.\n",
    "\n",
    "  2 - How many total people in data set?\n",
    "\n",
    "  3 - What is the earliest year of birth?\n",
    "\n",
    "  4 - How many years ago was this person born?\n",
    "\n",
    "  5 - Using only the data in the data set, determine if this date of birth correct.\n",
    "\n",
    "  6 - Explain the reasoning for the answer in a code comment or new markdown cell.\n",
    "\n",
    "  7 - What is the most recent data of birth?\n",
    "\n",
    "  8 - What percentage of the people do not have a listed date of birth?\n",
    "\n",
    "  9 - What is the length of the longest \"short\" after 1900?\n",
    "\n",
    "  10 - What is the length of the shortest \"movie\" after 1900?\n",
    "\n",
    "  11 - List of all of the genres represented.\n",
    "\n",
    "  12 - What is the higest rated comedy \"movie\" in the dataset? Note, if there is a tie, the tie shall be broken by the movie with the most votes.\n",
    "\n",
    "  13 - Who was the director of the movie?\n",
    "\n",
    "  14 - List, if any, the alternate titles for the movie.\n",
    "\n",
    "## **Stream Processing**\n",
    "\n",
    "Choose any five entities from the data set. These can be specific movies, actors, crews, etc, or more abstract concepts such as specific genres, etc. The main criteria is that the entities chosen must have a trackable wiki page. Set up a stream processing job that will track events for the chosen entities from the wikimedia Events Platform. These tracking jobs should provide some simple metrics. These metrics should be stored in a database or file (depending on the platform used). At least one of the metrics should be of the \"alert\" type (meaning some event that would require further action. For instance imagine wanting to be notified each time a specific user makes a change. Capture this \"alert\" and mimic an alerting system by routing these events to a different file/database.) These tables/data do not need to be shared, but the structure of the output should be clearly noted in the code and/or markdown cells. Additionally, a brief explanation/overview of this section should be provided in a seperate markdown cell or in the project readme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4be89187-c2eb-4224-a5ea-c83d9c370d74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62ffc95d-433d-4c91-b994-d6d0d18df9b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Population Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1f308db-ea66-4f9c-a9f3-0dc8aacfed8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create folder if not exists\n",
    "import os\n",
    "\n",
    "local_path = \"/Workspace/Users/mael.depreville@edu.ece.fr/big-data-processing-project/data\"\n",
    "\n",
    "os.makedirs(local_path, exist_ok=True)\n",
    "local_path\n",
    "\n",
    "# 2. Download files using shell \n",
    "files = [\n",
    "    \"name.basics.tsv.gz\",\n",
    "    \"title.akas.tsv.gz\",\n",
    "    \"title.basics.tsv.gz\",\n",
    "    \"title.crew.tsv.gz\",\n",
    "    \"title.episode.tsv.gz\",\n",
    "    \"title.principals.tsv.gz\",\n",
    "    \"title.ratings.tsv.gz\"\n",
    "]\n",
    "\n",
    "base_url = \"https://datasets.imdbws.com/\"\n",
    "\n",
    "for f in files:\n",
    "    url = base_url + f\n",
    "    out = f\"{local_path}/{f}\"\n",
    "    print(\"Downloading:\", f)\n",
    "    os.system(f\"wget -O {out} {url}\")\n",
    "\n",
    "# 3. Access data\n",
    "df = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .csv(f\"{local_path}/name.basics.tsv.gz\")\n",
    ")\n",
    "\n",
    "df.show(5)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
